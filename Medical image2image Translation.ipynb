{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from random import random\n",
    "\n",
    "# Data\n",
    "import tensorflow.image as tfi\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "# Model Layers\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "# Model Functions\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "# Optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Loss\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Model Visualization\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title=None):\n",
    "   \n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_ct_path = \"C:/Users/drewa/Downloads/Compressed/archive/Dataset/images/trainA\"\n",
    "root_mri_path = \"C:/Users/drewa/Downloads/Compressed/archive/Dataset/images/trainB\"\n",
    "ct_paths = sorted(glob(root_ct_path + '/*.png'))[:1000]\n",
    "mri_paths = sorted(glob(root_mri_path + '/*.jpg'))[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 1000it [00:27, 36.95it/s]\n"
     ]
    }
   ],
   "source": [
    "SIZE = 256\n",
    "ct_images, mri_images = np.zeros(shape=(len(ct_paths),SIZE,SIZE,3)), np.zeros(shape=(len(ct_paths),SIZE,SIZE,3))\n",
    "for i,(ct_path, mri_path) in tqdm(enumerate(zip(ct_paths, mri_paths)), desc='Loading'):\n",
    "    \n",
    "    ct_image = img_to_array(load_img(ct_path))\n",
    "    ct_image = tfi.resize(tf.cast(ct_image, tf.float32)/255., (SIZE, SIZE))\n",
    "    \n",
    "    mri_image = img_to_array(load_img(mri_path))\n",
    "    mri_image = tfi.resize(tf.cast(mri_image,tf.float32)/255., (SIZE, SIZE))\n",
    "    \n",
    "   \n",
    "    \n",
    "    ct_images[i] = ct_image\n",
    "    mri_images[i] = mri_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [ct_images, mri_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing\n",
    "for i in range(10):\n",
    "    id = np.random.randint(len(ct_images))\n",
    "    ct, mri = ct_images[id], mri_images[id]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    show_image(ct)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    show_image(mri)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(filters, layer, index):\n",
    "#     init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal', use_bias=False, name=\"Block_{}_Conv1\".format(index))(layer)\n",
    "    x = InstanceNormalization(axis=-1, name=\"Block_{}_Normalization1\".format(index))(x)\n",
    "    x = ReLU(name=\"Block_{}_ReLU\".format(index))(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal', use_bias=False, name=\"Block_{}_Conv2\".format(index))(x)\n",
    "    x = InstanceNormalization(axis=-1, name=\"Block_{}_Normalization2\".format(index))(x)\n",
    "    \n",
    "    x = concatenate([x, layer], name=\"Block_{}_Merge\".format(index))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, layer, size=3, strides=2, activation=None, index=None, norm=True):\n",
    "    x = Conv2D(filters, kernel_size=size, strides=strides, padding='same', kernel_initializer='he_normal', use_bias=False, name=\"Encoder_{}_Conv\".format(index))(layer)\n",
    "    if norm:\n",
    "        x = InstanceNormalization(axis=-1, name=\"Encoder_{}_Normalization\".format(index))(x)\n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=\"Encoder_{}_Activation\".format(index))(x)\n",
    "    else:\n",
    "        x = LeakyReLU( name=\"Encoder_{}_LeakyReLU\".format(index))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, layer, size=3, strides=2, index=None):\n",
    "    x = Conv2DTranspose(filters, kernel_size=size, strides=strides, padding='same', kernel_initializer='he_normal', use_bias=False, name=\"Decoder_{}_ConvT\".format(index))(layer)\n",
    "    x = InstanceNormalization(axis=-1, name=\"Decoder_{}_Normalization\".format(index))(x)\n",
    "    x = ReLU( name=\"Encoder_{}_ReLU\".format(index))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(n_resnet=9, name=\"Generator\"):\n",
    "    \n",
    "    inp_image = Input(shape=(SIZE, SIZE, 3), name=\"InputImage\")         # 256 x 256 x3\n",
    "    \n",
    "    x = downsample(64, inp_image, size=7, strides=1, index=1)           # 256 x 256 x 64\n",
    "    x = downsample(128, x, index=2)                                     # 128 x 128 x 128\n",
    "    x = downsample(256, x, index=3)                                     # 64 x 64 x 256\n",
    "    \n",
    "    for i in range(n_resnet):\n",
    "        x = ResidualBlock(256, x, index=i+4)                             # (64 x 64 x 256) x n_resnet\n",
    "    \n",
    "    x = upsample(128, x, index=13)                                       # 128 x 128 x 128\n",
    "    x = upsample(64, x, index=14)                                        # 256 x 256 x 64\n",
    "    x = downsample(3, x, size=7, strides=1, activation='tanh', index=15) # 256 x 256 x 3\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=inp_image,\n",
    "        outputs=x,\n",
    "        name=name\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(name='Discriminator'):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    src_img = Input(shape=(SIZE, SIZE, 3), name=\"InputImage\")     # 256 x 256 x 3\n",
    "    x = downsample(64, src_img, size=4, strides=2, index=1, norm=False) # 128 x 128 x 64\n",
    "    x = downsample(128, x, size=4, strides=2, index=2)            # 64 x 64 x 128\n",
    "    x = downsample(256, x, size=4, strides=2, index=3)            # 32 x 32 x 256\n",
    "    x = downsample(512, x, size=4, strides=2, index=4)            # 16 x 16 x 512\n",
    "    x = downsample(512, x, size=4, strides=2, index=5)            # 8 x 8 x 512 \n",
    "    patch_out = Conv2D(1, kernel_size=4, padding='same', kernel_initializer=init, use_bias=False)(x) # 8 x 8 x 1\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=src_img,\n",
    "        outputs=patch_out,\n",
    "        name=name\n",
    "    )\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "        loss_weights=[0.5]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineModel(g_model1, g_model2, d_model, name):\n",
    "    # train the Generator\n",
    "    g_model1.trainable = True\n",
    "\n",
    "    # Stop the Discriminator and 2nd Generator\n",
    "    d_model.trainable = False\n",
    "    g_model2.trainable = False\n",
    "    \n",
    "    # Adversarial Loss\n",
    "    input_gen = Input(shape=(SIZE, SIZE, 3))\n",
    "    gen_1_out = g_model1(input_gen)\n",
    "    dis_out = d_model(gen_1_out)\n",
    "    \n",
    "    # Identity Loss\n",
    "    input_id = Input(shape=(SIZE, SIZE, 3))\n",
    "    output_id = g_model1(input_id)\n",
    "    \n",
    "    # Cycle Loss - Forward\n",
    "    output_f = g_model2(gen_1_out)\n",
    "    \n",
    "    # Cycle Loss - Backward\n",
    "    gen_2_out = g_model2(input_id)\n",
    "    output_b = g_model1(gen_2_out)\n",
    "    \n",
    "    # Final Model \n",
    "    model = Model(\n",
    "        inputs=[input_gen, input_id],\n",
    "        outputs=[dis_out, output_id, output_f, output_b],\n",
    "        name=name\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=['mse', 'mae', 'mae', 'mae'],\n",
    "        loss_weights=[1,5,10,10],\n",
    "        optimizer= Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(n_samples, dataset):\n",
    "    ix = np.random.randint(0,dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones(shape=(n_samples, 8, 8, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, dataset):\n",
    "    X = g_model.predict(dataset)\n",
    "    y = np.zeros(shape=(len(dataset), 8, 8, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            ix = np.random.randint(0,len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(g_AB, g_BA,n_images=1):\n",
    "    for i in range(n_images):\n",
    "        \n",
    "        id = np.random.randint(len(ct_images))\n",
    "        ct, mri = ct_images[id], mri_images[id]\n",
    "        ct_pred, mri_pred = g_BA.predict(tf.expand_dims(mri,axis=0))[0], g_AB.predict(tf.expand_dims(ct,axis=0))[0]\n",
    "        \n",
    "        plt.figure(figsize=(10,8))\n",
    "        \n",
    "        plt.subplot(1,4,1)\n",
    "        show_image(ct, title='Original CT')\n",
    "        \n",
    "        plt.subplot(1,4,2)\n",
    "        show_image(mri_pred, title='Generated Mri')\n",
    "        \n",
    "        plt.subplot(1,4,3)\n",
    "        show_image(mri, title='Original Mri')\n",
    "        \n",
    "        plt.subplot(1,4,4)\n",
    "        show_image(ct_pred, title='Genrated CT')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model_A, d_model_B, gen_AB, gen_BA, c_AB, c_BA, epochs=20, chunk=5):\n",
    "    \n",
    "    n_epochs, n_batch = epochs, 1\n",
    "    \n",
    "    trainA, trainB = dataset\n",
    "    poolA, poolB = list(), list()\n",
    "    \n",
    "    # in simple words, we are going through the whole data.\n",
    "    bat_per_epoch = int(len(trainA)/n_batch)\n",
    "    n_steps = bat_per_epoch\n",
    "    \n",
    "    for j in tqdm(range(1,epochs+1), desc=\"Epochs\"):\n",
    "        for i in range(n_steps):\n",
    "            \n",
    "            # Let's get some real data in hand.\n",
    "            X_realA, y_realA = generate_real_samples(n_batch, trainA)\n",
    "            X_realB, y_realB = generate_real_samples(n_batch, trainB)\n",
    "\n",
    "            # use our generators to generate some fake data.\n",
    "            X_fakeA, y_fakeA = generate_fake_samples(gen_BA, X_realB)\n",
    "            X_fakeB, y_fakeB = generate_fake_samples(gen_AB, X_realA)\n",
    "            \n",
    "            # create a pool of images. You can also understand it like a replay buffer.\n",
    "            X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "            X_fakeB = update_image_pool(poolA, X_fakeB)\n",
    "            \n",
    "            \n",
    "            # finally training the gen 2 and getting the losses.\n",
    "            gen_loss2, _, _, _, _ = c_BA.train_on_batch(\n",
    "                [X_realB, X_realA],\n",
    "                [y_realB, X_realA, X_realB, X_realA]\n",
    "            )\n",
    "            \n",
    "            # It's time for our discriminator to win our generator.\n",
    "            dA_loss_1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "            dA_loss_2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "            \n",
    "            # one cycle is completed, let's move to second cycle.\n",
    "            gen_loss1, _, _, _, _ = c_AB.train_on_batch(\n",
    "                [X_realA, X_realB],\n",
    "                [y_realA, X_realB, X_realA, X_realB]\n",
    "            )\n",
    "            \n",
    "            # again, let's give some power to our discriminators.\n",
    "            dB_loss_1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "            dB_loss_2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "\n",
    "        if (j%chunk)==0:\n",
    "            show_preds(gen_AB, gen_BA, n_images=1)\n",
    "            gen_AB.save(\"GeneratorCtoM.C5\")\n",
    "            gen_BA.save(\"GeneratorMtoC.C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the generators.\n",
    "g_AB = Generator(name=\"GeneratorAB\")\n",
    "g_BA = Generator(name=\"GeneratorBA\")\n",
    "\n",
    "# the respective discriminators.\n",
    "d_A = Discriminator(name=\"DiscriminatorA\")\n",
    "d_B = Discriminator(name=\"DiscriminatorB\")\n",
    "\n",
    "# finally, combining them.\n",
    "c_AB = CombineModel(g_AB, g_BA, d_B, name=\"GanAB\")\n",
    "c_BA = CombineModel(g_BA, g_AB, d_A, name=\"GanBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # it's time to give them the superior knowledge.\n",
    "train(d_A, d_B, g_AB, g_BA, c_AB, c_BA, epochs=30, chunk=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_AB.save(\"GeneratorCtoM.C5\")\n",
    "g_BA.save(\"GeneratorMtoC.C5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CtoM_gen = load_model(\"C:/Users/drewa/Desktop/NeuralNetworkProject/GeneratorCtoM.C5\")\n",
    "MtoC_gen = load_model(\"C:/Users/drewa/Desktop/NeuralNetworkProject/GeneratorMtoC.C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds(CtoM_gen, MtoC_gen, n_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CtoM_gen_25 = load_model(\"C:/Users/drewa/Desktop/NeuralNetworkProject/GeneratorCtoM_25.C5\")\n",
    "MtoC_gen_25 = load_model(\"C:/Users/drewa/Desktop/NeuralNetworkProject/GeneratorMtoC_25.C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds(CtoM_gen_25, MtoC_gen_25, n_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87143985a04ba9417d956ebcda545cff07aa2b87bfec6459c5391b1bbda451c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
